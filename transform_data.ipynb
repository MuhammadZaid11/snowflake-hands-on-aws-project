{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c753b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "WARNING: package sun.security.action not in java.base\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/02/07 17:23:27 WARN Utils: Your hostname, codespaces-ee7d44, resolves to a loopback address: 127.0.0.1; using 10.0.1.87 instead (on interface eth0)\n",
      "26/02/07 17:23:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/07 17:23:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "WARNING: A terminally deprecated method in sun.misc.Unsafe has been called\n",
      "WARNING: sun.misc.Unsafe::arrayBaseOffset has been called by org.apache.spark.unsafe.Platform (file:/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/jars/spark-unsafe_2.13-4.1.1.jar)\n",
      "WARNING: Please consider reporting this to the maintainers of class org.apache.spark.unsafe.Platform\n",
      "WARNING: sun.misc.Unsafe::arrayBaseOffset will be removed in a future release\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyspark as ps\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SnowflakeDataLoad\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a39ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"/workspaces/snowflake-hands-on-aws-project/Data/netflix_titles.csv\"\n",
    "print(os.path.exists(path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a9402",
   "metadata": {},
   "source": [
    "### First Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57266848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+------------------+---------+\n",
      "|Unnamed: 0|         Adj Close|             Close|              High|               Low|              Open|   Volume|\n",
      "+----------+------------------+------------------+------------------+------------------+------------------+---------+\n",
      "|1980-12-12|0.0988344699144363|0.1283479928970337|0.1289059966802597|0.1283479928970337|0.1283479928970337|469033600|\n",
      "|1980-12-15|0.0936782136559486|0.1216519996523857|0.1222100034356117|0.1216519996523857|0.1222100034356117|175884800|\n",
      "|1980-12-16|0.0868024080991745|0.1127230003476142|0.1132809966802597|0.1127230003476142|0.1132809966802597|105728000|\n",
      "|1980-12-17|0.0889508724212646|0.1155129969120025|0.1160710006952285|0.1155129969120025|0.1155129969120025| 86441600|\n",
      "|1980-12-18|0.0915297642350196|0.1188620030879974|0.1194199994206428|0.1188620030879974|0.1188620030879974| 73449600|\n",
      "|1980-12-19|0.0971156954765319|0.1261159926652908|0.1266739964485168|0.1261159926652908|0.1261159926652908| 48630400|\n",
      "|1980-12-22|0.1018423289060592|0.1322540044784546|0.1328130066394806|0.1322540044784546|0.1322540044784546| 37363200|\n",
      "|1980-12-23|0.1061399802565574|0.1378349959850311|0.1383929997682571|0.1378349959850311|0.1378349959850311| 46950400|\n",
      "|1980-12-24|0.1117258593440055|0.1450890004634857|0.1456470042467117|0.1450890004634857|0.1450890004634857| 48003200|\n",
      "|1980-12-26|0.1220391914248466|0.1584820002317428|0.1590400040149688|0.1584820002317428|0.1584820002317428| 55574400|\n",
      "|1980-12-29|0.1237579360604286|0.1607140004634857|0.1612720042467117|0.1607140004634857|0.1607140004634857| 93161600|\n",
      "|1980-12-30|0.1207501366734504| 0.156808003783226|0.1573659926652908| 0.156808003783226|0.1573659926652908| 68880000|\n",
      "|1980-12-31|0.1173126175999641|0.1523440033197403|0.1529020071029663|0.1523440033197403|0.1529020071029663| 35750400|\n",
      "|1981-01-02|0.1186016723513603|0.1540179997682571|0.1551340073347091|0.1540179997682571|0.1540179997682571| 21660800|\n",
      "|1981-01-05|0.1160235404968261|0.1506700068712234|0.1512279957532882|0.1506700068712234|0.1512279957532882| 35728000|\n",
      "|1981-01-06|0.1108664572238922|0.1439729928970337|0.1445309966802597|0.1439729928970337|0.1445309966802597| 45158400|\n",
      "|1981-01-07|0.1061399802565574|0.1378349959850311|0.1383929997682571|0.1378349959850311|0.1383929997682571| 55686400|\n",
      "|1981-01-08|0.1039915159344673|0.1350450068712234|0.1356029957532882|0.1350450068712234|0.1356029957532882| 39827200|\n",
      "|1981-01-09|0.1095774844288826|0.1422989964485168|0.1428570002317428|0.1422989964485168|0.1422989964485168| 21504000|\n",
      "|1981-01-12|0.1087180748581886| 0.141183003783226|0.1422989964485168| 0.141183003783226|0.1422989964485168| 23699200|\n",
      "+----------+------------------+------------------+------------------+------------------+------------------+---------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 233, in manager\n",
      "    code = worker(sock, authenticated)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 87, in worker\n",
      "    outfile.flush()\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "path1 = \"/workspaces/snowflake-hands-on-aws-project/Data/apple_stock.csv\"\n",
    "pdf1 = pd.read_csv(path1)\n",
    "df1 = spark.createDataFrame(pdf1)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "803bbe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Unnamed: 0: string (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- Volume: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()\n",
    "# pdf1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f45d19",
   "metadata": {},
   "source": [
    "### Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7637fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+---------------+--------------------+-------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|       director|                cast|      country|        date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "|     s1|  Movie|Dick Johnson Is Dead|Kirsten Johnson|                 nan|United States|September 25, 2021|        2020| PG-13|   90 min|       Documentaries|As her father nea...|\n",
      "|     s2|TV Show|       Blood & Water|            nan|Ama Qamata, Khosi...| South Africa|September 24, 2021|        2021| TV-MA|2 Seasons|International TV ...|After crossing pa...|\n",
      "|     s3|TV Show|           Ganglands|Julien Leclercq|Sami Bouajila, Tr...|          nan|September 24, 2021|        2021| TV-MA| 1 Season|Crime TV Shows, I...|To protect his fa...|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 3 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 233, in manager\n",
      "    code = worker(sock, authenticated)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 87, in worker\n",
      "    outfile.flush()\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Spark\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "'''\n",
    "# Read CSV with pandas\n",
    "path = \"/workspaces/snowflake-hands-on-aws-project/Data/netflix_titles.csv\"\n",
    "pdf = pd.read_csv(path)\n",
    "'''\n",
    "# Convert to Spark DataFrame\n",
    "df = spark.createDataFrame(pdf)\n",
    "\n",
    "df.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b491af73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|       director|                cast|      country|date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|     s1|  Movie|Dick Johnson Is Dead|Kirsten Johnson|                 nan|United States|2021-09-25|        2020| PG-13|   90 min|       Documentaries|As her father nea...|\n",
      "|     s2|TV Show|       Blood & Water|            nan|Ama Qamata, Khosi...| South Africa|2021-09-24|        2021| TV-MA|2 Seasons|International TV ...|After crossing pa...|\n",
      "|     s3|TV Show|           Ganglands|Julien Leclercq|Sami Bouajila, Tr...|          nan|2021-09-24|        2021| TV-MA| 1 Season|Crime TV Shows, I...|To protect his fa...|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 3 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 233, in manager\n",
      "    code = worker(sock, authenticated)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 87, in worker\n",
      "    outfile.flush()\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Fill missing string columns\n",
    "df2 = df2.fillna({\n",
    "    \"director\": \"Unknown\",\n",
    "    \"cast\": \"Unknown\",\n",
    "    \"country\": \"Unknown\",\n",
    "    \"rating\": \"Not Rated\",\n",
    "    \"duration\": \"Unknown\"\n",
    "})\n",
    "\n",
    "#  Convert date_added to proper Date type\n",
    "df2 = df2.withColumn(\n",
    "    \"date_added\",\n",
    "    F.to_date(F.col(\"date_added\"), \"MMMM d, yyyy\")\n",
    ")\n",
    "\n",
    "#  Handle remaining null date values\n",
    "df2 = df2.fillna({\n",
    "    \"date_added\": \"1900-01-01\"\n",
    "})\n",
    "\n",
    "#  Trim string columns (very important in real projects)\n",
    "string_cols = [\"type\", \"title\", \"director\", \"cast\", \"country\", \"rating\", \"listed_in\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dfc6969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+---------------+--------------------+-------------+-------------------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|       director|                cast|      country|         date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+-------------------+------------+------+---------+--------------------+--------------------+\n",
      "|     s1|  Movie|Dick Johnson Is Dead|Kirsten Johnson|             Unknown|United States|2021-09-25 00:00:00|        2020| PG-13|   90 min|       Documentaries|As her father nea...|\n",
      "|     s2|TV Show|       Blood & Water|        Unknown|Ama Qamata, Khosi...| South Africa|2021-09-24 00:00:00|        2021| TV-MA|2 Seasons|International TV ...|After crossing pa...|\n",
      "|     s3|TV Show|           Ganglands|Julien Leclercq|Sami Bouajila, Tr...|          nan|2021-09-24 00:00:00|        2021| TV-MA| 1 Season|Crime TV Shows, I...|To protect his fa...|\n",
      "+-------+-------+--------------------+---------------+--------------------+-------------+-------------------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 3 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 233, in manager\n",
      "    code = worker(sock, authenticated)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 87, in worker\n",
      "    outfile.flush()\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c374c310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: timestamp (nullable = true)\n",
      " |-- release_year: long (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a84e83f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperationException",
     "evalue": "getSubject is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnsupportedOperationException\u001b[39m             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdf2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnetflix_cleaned.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/sql/readwriter.py:2146\u001b[39m, in \u001b[36mDataFrameWriter.csv\u001b[39m\u001b[34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[39m\n\u001b[32m   2127\u001b[39m \u001b[38;5;28mself\u001b[39m.mode(mode)\n\u001b[32m   2128\u001b[39m \u001b[38;5;28mself\u001b[39m._set_opts(\n\u001b[32m   2129\u001b[39m     compression=compression,\n\u001b[32m   2130\u001b[39m     sep=sep,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2144\u001b[39m     lineSep=lineSep,\n\u001b[32m   2145\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2146\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/py4j/java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:269\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    265\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    267\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    268\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mUnsupportedOperationException\u001b[39m: getSubject is not supported"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "df2.write.csv(\"netflix_cleaned.csv\", header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a190487",
   "metadata": {},
   "source": [
    "### Third Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a0dd2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-------------+--------------------+----------------+--------------+--------------+------------+--------------------+--------------------+-------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+\n",
      "|       product_title|product_rating|total_reviews|purchased_last_month|discounted_price|original_price|is_best_seller|is_sponsored|          has_coupon|buy_box_availability|delivery_date| sustainability_tags|   product_image_url|    product_page_url|  data_collected_at|   product_category|discount_percentage|\n",
      "+--------------------+--------------+-------------+--------------------+----------------+--------------+--------------+------------+--------------------+--------------------+-------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+\n",
      "|BOYA BOYALINK 2 W...|           4.6|        375.0|               300.0|           89.68|         159.0|      No Badge|   Sponsored|Save 15%  with co...|         Add to cart|   2025-09-01|       Carbon impact|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|             Phones|               43.6|\n",
      "|LISEN USB C to Li...|           4.3|       2457.0|              6000.0|            9.99|         15.99|      No Badge|   Sponsored|           No Coupon|         Add to cart|   2025-08-29|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|            Laptops|              37.52|\n",
      "|DJI Mic 2 (2 TX +...|           4.6|       3044.0|              2000.0|           314.0|         349.0|      No Badge|   Sponsored|           No Coupon|         Add to cart|   2025-09-01|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|            Laptops|              10.03|\n",
      "|Apple AirPods Pro...|           4.6|      35882.0|             10000.0|          162.24|        162.24|   Best Seller|     Organic|           No Coupon|                 nan|          nan|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|             Phones|                0.0|\n",
      "|Apple AirTag 4 Pa...|           4.8|      28988.0|             10000.0|           72.74|         72.74|      No Badge|     Organic|           No Coupon|                 nan|          nan|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|             Phones|                0.0|\n",
      "|Texas Instruments...|           4.6|      44522.0|            100000.0|           99.95|         99.95|   Best Seller|     Organic|           No Coupon|                 nan|          nan|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|  Other Electronics|                0.0|\n",
      "|Apple AirPods 4 W...|           4.5|      13466.0|             10000.0|           88.11|         88.11|      No Badge|     Organic|           No Coupon|                 nan|          nan|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|             Phones|                0.0|\n",
      "|Apple AirTag. Kee...|           4.6|      38105.0|             10000.0|           23.04|         23.04|   Best Seller|     Organic|           No Coupon|                 nan|          nan|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|             Phones|                0.0|\n",
      "|Complete Protect:...|           4.0|       4380.0|                 NaN|           16.99|         16.99|      No Badge|     Organic|Save 50%  with co...|                 nan|          nan|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|  Other Electronics|                0.0|\n",
      "|Apple iPad 11-inc...|           4.7|       7308.0|             10000.0|          284.05|        284.05|   Best Seller|     Organic|           No Coupon|                 nan|          nan|   Energy efficiency|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|            Cameras|                0.0|\n",
      "|Amazon Basics 48-...|           4.7|     865598.0|            100000.0|           14.99|         14.99|   Best Seller|     Organic|           No Coupon|         Add to cart|   2025-08-29|Safer chemicals +...|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|            Laptops|                0.0|\n",
      "|Apple 2025 MacBoo...|           4.8|       1914.0|             10000.0|          880.95|        880.95|   Best Seller|     Organic|           No Coupon|                 nan|          nan|   Energy efficiency|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|            Laptops|                0.0|\n",
      "|Transformers TF-T...|           4.2|        152.0|               100.0|           29.99|         29.99|      No Badge|   Sponsored|           No Coupon|         Add to cart|   2025-09-01|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|             Phones|                0.0|\n",
      "|Seagate IronWolf ...|           4.4|      12076.0|              1000.0|          249.99|        249.99|      No Badge|   Sponsored|           No Coupon|         Add to cart|   2025-09-01|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|            Storage|                0.0|\n",
      "|Peak Design Slide...|           4.7|       7235.0|               500.0|           69.95|         69.95|      No Badge|   Sponsored|           No Coupon|         Add to cart|   2025-08-29|      Small Business|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|            Cameras|                0.0|\n",
      "|Texas Instruments...|           4.7|      48468.0|            100000.0|           17.45|         17.45|   Best Seller|     Organic|           No Coupon|                 nan|          nan|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|  Other Electronics|                0.0|\n",
      "|Amazon Basics Mul...|           4.8|     198512.0|             80000.0|           39.97|         39.97|   Best Seller|     Organic|           No Coupon|         Add to cart|   2025-09-01|1 sustainability ...|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|Printers & Scanners|                0.0|\n",
      "|Amazon Basics AAA...|           4.7|     625776.0|            100000.0|           14.49|         14.49|   Best Seller|     Organic|           No Coupon|         Add to cart|   2025-08-29|Safer chemicals +...|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|            Laptops|                0.0|\n",
      "|Amazon Basics Cle...|           4.8|      88965.0|            100000.0|           16.98|         16.98|   Best Seller|     Organic|           No Coupon|         Add to cart|   2025-08-29|                 nan|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|  Other Electronics|                0.0|\n",
      "|Roku Streaming St...|           4.6|       1909.0|             10000.0|           33.51|         33.51|      No Badge|     Organic|           No Coupon|                 nan|          nan|    Works with Alexa|https://m.media-a...|https://www.amazo...|2025-08-21 11:14:29|       TV & Display|                0.0|\n",
      "+--------------------+--------------+-------------+--------------------+----------------+--------------+--------------+------------+--------------------+--------------------+-------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 233, in manager\n",
      "    code = worker(sock, authenticated)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 87, in worker\n",
      "    outfile.flush()\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "path2 = \"/workspaces/snowflake-hands-on-aws-project/Data/amazon_products_sales_data_cleaned.csv\"\n",
    "pdf3 = pd.read_csv(path2)\n",
    "df3 = spark.createDataFrame(pdf3)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa8f4f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_title               0\n",
       "product_rating           1024\n",
       "total_reviews            1024\n",
       "purchased_last_month    10511\n",
       "discounted_price         2062\n",
       "original_price           2062\n",
       "is_best_seller              0\n",
       "is_sponsored                0\n",
       "has_coupon                  0\n",
       "buy_box_availability    14653\n",
       "delivery_date           11983\n",
       "sustainability_tags     39267\n",
       "product_image_url           0\n",
       "product_page_url         2069\n",
       "data_collected_at           0\n",
       "product_category            0\n",
       "discount_percentage      2062\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcec0daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- product_rating: double (nullable = false)\n",
      " |-- total_reviews: double (nullable = false)\n",
      " |-- purchased_last_month: double (nullable = false)\n",
      " |-- discounted_price: double (nullable = false)\n",
      " |-- original_price: double (nullable = false)\n",
      " |-- is_best_seller: string (nullable = true)\n",
      " |-- is_sponsored: string (nullable = true)\n",
      " |-- has_coupon: string (nullable = true)\n",
      " |-- buy_box_availability: string (nullable = false)\n",
      " |-- delivery_date: string (nullable = false)\n",
      " |-- sustainability_tags: string (nullable = false)\n",
      " |-- product_image_url: string (nullable = true)\n",
      " |-- product_page_url: string (nullable = false)\n",
      " |-- data_collected_at: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- discount_percentage: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a93aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fill numeric nulls\n",
    "numeric_fill = {\n",
    "    \"product_rating\": 0,\n",
    "    \"total_reviews\": 0,\n",
    "    \"purchased_last_month\": 0,\n",
    "    \"discounted_price\": 0,\n",
    "    \"original_price\": 0,\n",
    "    \"discount_percentage\": 0\n",
    "}\n",
    "df3 = df3.fillna(numeric_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84821fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `delivery_date ` cannot be resolved. Did you mean one of the following? [`product_title`, `product_rating`, `total_reviews`, `purchased_last_month`, `discounted_price`, `original_price`, `is_best_seller`, `is_sponsored`, `has_coupon`, `buy_box_availability`, `delivery_date`, `sustainability_tags`, `product_image_url`, `product_page_url`, `data_collected_at`, `product_category`, `discount_percentage`]. SQLSTATE: 42703",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Step 2: Fill string/object nulls\u001b[39;00m\n\u001b[32m      2\u001b[39m string_fill = {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbuy_box_availability\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdelivery_date\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df3 = \u001b[43mdf3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/sql/classic/dataframe.py:1286\u001b[39m, in \u001b[36mDataFrame.fillna\u001b[39m\u001b[34m(self, value, subset)\u001b[39m\n\u001b[32m   1283\u001b[39m     value = \u001b[38;5;28mfloat\u001b[39m(value)\n\u001b[32m   1285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.sparkSession)\n\u001b[32m   1287\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m subset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28mself\u001b[39m._jdf.na().fill(value), \u001b[38;5;28mself\u001b[39m.sparkSession)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/py4j/java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/snowflake-hands-on-aws-project/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:269\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    265\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    267\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    268\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `delivery_date ` cannot be resolved. Did you mean one of the following? [`product_title`, `product_rating`, `total_reviews`, `purchased_last_month`, `discounted_price`, `original_price`, `is_best_seller`, `is_sponsored`, `has_coupon`, `buy_box_availability`, `delivery_date`, `sustainability_tags`, `product_image_url`, `product_page_url`, `data_collected_at`, `product_category`, `discount_percentage`]. SQLSTATE: 42703"
     ]
    }
   ],
   "source": [
    "# Step 2: Fill string/object nulls\n",
    "string_fill = {\n",
    "    \"buy_box_availability\": \"Unknown\",\n",
    "    \"delivery_date\": \"Unknown\",\n",
    "    \"sustainability_tags\": \"Unknown\",\n",
    "    \"product_page_url\": \"Unknown\",\n",
    "    \"buy_box_availability\": \"Unknown\",\n",
    "    \"product_page_url\": \"Unknown\",\n",
    "    \"sustainability_tags\": \"Unknown\",\n",
    "    \"delivery_date \": \"Unknown\"\n",
    "    \n",
    "    \n",
    "}\n",
    "df3 = df3.fillna(string_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "813ad5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- product_rating: double (nullable = false)\n",
      " |-- total_reviews: double (nullable = false)\n",
      " |-- purchased_last_month: double (nullable = false)\n",
      " |-- discounted_price: double (nullable = false)\n",
      " |-- original_price: double (nullable = false)\n",
      " |-- is_best_seller: string (nullable = true)\n",
      " |-- is_sponsored: string (nullable = true)\n",
      " |-- has_coupon: string (nullable = true)\n",
      " |-- buy_box_availability: string (nullable = false)\n",
      " |-- delivery_date: string (nullable = false)\n",
      " |-- sustainability_tags: string (nullable = false)\n",
      " |-- product_image_url: string (nullable = true)\n",
      " |-- product_page_url: string (nullable = false)\n",
      " |-- data_collected_at: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- discount_percentage: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42675"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.printSchema()\n",
    "df3.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b128d5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save all three datasets\n",
    "\n",
    "df3.toPandas().to_csv(\"amazon_products_cleaned.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"All datasets saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa92a328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 8807 entries, 0 to 8806\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   show_id       8807 non-null   str  \n",
      " 1   type          8807 non-null   str  \n",
      " 2   title         8807 non-null   str  \n",
      " 3   director      8807 non-null   str  \n",
      " 4   cast          8807 non-null   str  \n",
      " 5   country       7976 non-null   str  \n",
      " 6   date_added    8709 non-null   str  \n",
      " 7   release_year  8807 non-null   int64\n",
      " 8   rating        8807 non-null   str  \n",
      " 9   duration      8807 non-null   str  \n",
      " 10  listed_in     8807 non-null   str  \n",
      " 11  description   8807 non-null   str  \n",
      "dtypes: int64(1), str(11)\n",
      "memory usage: 825.8 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pt =\"/workspaces/snowflake-hands-on-aws-project/Data/netflix_cleaned.csv\"\n",
    "dt = pd.read_csv(pt)\n",
    "dt.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
